"""
NLRP3æ•°æ®é‡‡é›† - ä¼˜åŒ–ç‰ˆ
å…³é”®æ”¹è¿›ï¼š
1. å¤§å¹…å¢åŠ NLRP3åŸå§‹æ•°æ®é‡ï¼ˆè€ƒè™‘é¢„å¤„ç†æŸå¤±ï¼‰
2. æ›´æ¿€è¿›çš„è¿‡é‡‡æ ·ç­–ç•¥
3. æ›´å…¨é¢çš„é¶ç‚¹æœç´¢
"""
import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path
import time

project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

from src.utils import setup_logger, load_data_config, log_section


class OptimizedDataCollector:
    """ä¼˜åŒ–çš„æ•°æ®é‡‡é›†å™¨ - ç¡®ä¿è¶³å¤Ÿçš„åŸå§‹æ•°æ®"""
    
    def __init__(self, config: dict):
        self.config = config
        self.logger = setup_logger("Optimized_Data_Collector")
        
        # ç›®æ ‡å‚æ•°ï¼ˆè€ƒè™‘å„é˜¶æ®µæŸå¤±ï¼‰
        self.target_final_active = 900
        self.target_ratio = 3.0
        
        # é¢„ä¼°æŸå¤±ç‡
        self.loss_rates = {
            'unit_conversion': 0.23,    # å•ä½è½¬æ¢å¤±è´¥ç‡
            'standardization': 0.01,    # æ ‡å‡†åŒ–å¤±è´¥ç‡
            'deduplication': 0.23,      # å»é‡æŸå¤±ç‡
            'labeling': 0.45,           # æ ‡ç­¾åˆ†é…ï¼ˆ55%å˜æ´»æ€§ï¼‰
        }
        
        # è®¡ç®—éœ€è¦çš„åŸå§‹æ•°æ®é‡
        self.calculate_raw_data_needed()
        
        # æ£€æŸ¥ChEMBL
        try:
            from chembl_webresource_client.new_client import new_client
            self.client_available = True
            self.chembl = new_client
            self.logger.info("âœ“ ChEMBLå®¢æˆ·ç«¯å¯ç”¨")
        except ImportError:
            self.client_available = False
            self.logger.warning("âœ— ChEMBLä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç¤ºä¾‹æ•°æ®")
    
    def calculate_raw_data_needed(self):
        """è®¡ç®—éœ€è¦é‡‡é›†çš„åŸå§‹æ•°æ®é‡"""
        self.logger.info(f"\n{'='*70}")
        self.logger.info("æ•°æ®éœ€æ±‚è®¡ç®—")
        self.logger.info(f"{'='*70}")
        
        # åå‘è®¡ç®—
        needed = self.target_final_active
        
        self.logger.info(f"\né¢„æœŸæŸå¤±ç‡:")
        for stage, rate in self.loss_rates.items():
            needed = needed / (1 - rate)
            self.logger.info(f"  {stage}: {rate*100:.0f}% â†’ éœ€è¦ {int(needed)}")
        
        # æœ€ç»ˆéœ€è¦çš„NLRP3åŸå§‹æ•°æ®ï¼ˆå†åŠ 20%å®‰å…¨è¾¹é™…ï¼‰
        self.raw_nlrp3_needed = int(needed * 1.2)
        
        # éæ´»æ€§æ•°æ®ï¼ˆç›®æ ‡3å€ï¼Œä¹Ÿéœ€è¦è¿‡é‡‡æ ·ï¼‰
        self.raw_inactive_needed = int(self.target_final_active * self.target_ratio * 1.5)
        
        self.logger.info(f"\nğŸ“Š æœ€ç»ˆé‡‡é›†ç›®æ ‡:")
        self.logger.info(f"  NLRP3æ•°æ®: {self.raw_nlrp3_needed} æ¡")
        self.logger.info(f"  éæ´»æ€§æ•°æ®: {self.raw_inactive_needed} æ¡")
        self.logger.info(f"  æ€»è®¡: {self.raw_nlrp3_needed + self.raw_inactive_needed} æ¡")
    
    def download_nlrp3_data_comprehensive(self) -> pd.DataFrame:
        """
        å…¨é¢ä¸‹è½½NLRP3æ•°æ®
        
        ç­–ç•¥ï¼š
        1. æœç´¢æ‰€æœ‰NLRP3ç›¸å…³é¶ç‚¹
        2. ä¸‹è½½æ‰€æœ‰æµ‹é‡ç±»å‹ï¼ˆä¸åªIC50ï¼‰
        3. ä¸é™åˆ¶organismï¼ˆåŒ…æ‹¬å°é¼ ç­‰ï¼‰
        """
        if not self.client_available:
            return pd.DataFrame()
        
        log_section(self.logger, "æ­¥éª¤1: å…¨é¢ä¸‹è½½NLRP3æ•°æ®")
        
        try:
            # æœç´¢æ‰€æœ‰NLRP3ç›¸å…³é¶ç‚¹
            search_terms = ['NLRP3', 'NALP3', 'Cryopyrin', 'CIAS1']
            
            all_targets = []
            for term in search_terms:
                try:
                    targets = self.chembl.target.filter(
                        target_synonym__icontains=term
                    ).only(['target_chembl_id', 'pref_name', 'organism', 'target_type'])
                    all_targets.extend(list(targets))
                except:
                    continue
            
            # å»é‡
            unique_targets = {t['target_chembl_id']: t for t in all_targets}
            
            self.logger.info(f"æ‰¾åˆ° {len(unique_targets)} ä¸ªNLRP3ç›¸å…³é¶ç‚¹:")
            for target_id, target in unique_targets.items():
                self.logger.info(f"  {target_id}: {target.get('pref_name', 'N/A')} "
                               f"({target.get('organism', 'N/A')})")
            
            # ä¸‹è½½æ‰€æœ‰é¶ç‚¹çš„æ´»æ€§æ•°æ®
            all_data = []
            
            for target_id, target in unique_targets.items():
                try:
                    self.logger.info(f"\nä¸‹è½½ {target_id} æ•°æ®...")
                    
                    # ä¸é™åˆ¶æµ‹é‡ç±»å‹ï¼Œä¸‹è½½æ‰€æœ‰
                    activities = self.chembl.activity.filter(
                        target_chembl_id=target_id
                    ).only([
                        'molecule_chembl_id',
                        'canonical_smiles',
                        'standard_type',
                        'standard_relation',
                        'standard_value',
                        'standard_units',
                        'pchembl_value',
                        'data_validity_comment'
                    ])
                    
                    data = list(activities)
                    
                    if data:
                        df_temp = pd.DataFrame(data)
                        df_temp['data_source'] = 'NLRP3_Target'
                        df_temp['source_detail'] = f"{target_id}_{target.get('organism', 'Unknown')}"
                        all_data.append(df_temp)
                        self.logger.info(f"  âœ“ è·å– {len(df_temp)} æ¡")
                    
                    time.sleep(0.5)
                    
                except Exception as e:
                    self.logger.warning(f"  ä¸‹è½½ {target_id} å¤±è´¥: {e}")
                    continue
            
            if all_data:
                df_all = pd.concat(all_data, ignore_index=True)
                
                # å»é‡ï¼ˆåŒä¸€åŒ–åˆç‰©å¯èƒ½åœ¨å¤šä¸ªé¶ç‚¹ä¸­ï¼‰
                initial_count = len(df_all)
                df_all = df_all.drop_duplicates(
                    subset=['molecule_chembl_id', 'standard_type', 'standard_value'],
                    keep='first'
                )
                
                self.logger.info(f"\nâœ“ NLRP3æ•°æ®é‡‡é›†å®Œæˆ:")
                self.logger.info(f"  åŸå§‹: {initial_count}")
                self.logger.info(f"  å»é‡å: {len(df_all)}")
                self.logger.info(f"  ç›®æ ‡: {self.raw_nlrp3_needed}")
                
                if len(df_all) < self.raw_nlrp3_needed:
                    shortage = self.raw_nlrp3_needed - len(df_all)
                    self.logger.warning(f"  âš ï¸  æ•°æ®ä¸è¶³ {shortage} æ¡")
                    self.logger.warning(f"  å°†ç”¨ç¤ºä¾‹æ•°æ®è¡¥å……")
                
                return df_all
            else:
                self.logger.warning("æœªæ‰¾åˆ°NLRP3æ•°æ®")
                return pd.DataFrame()
            
        except Exception as e:
            self.logger.error(f"ä¸‹è½½NLRP3æ•°æ®å¤±è´¥: {e}")
            import traceback
            self.logger.debug(traceback.format_exc())
            return pd.DataFrame()
    
    def sample_negative_compounds_aggressive(self, n_needed: int) -> pd.DataFrame:
        """
        æ›´æ¿€è¿›çš„è´Ÿæ ·æœ¬é‡‡æ ·
        
        æ”¹è¿›ï¼š
        1. æ›´å¤šé¶ç‚¹å®¶æ—
        2. æ›´å¤§çš„é‡‡æ ·é‡
        3. åŒ…å«æ›´å¤šæµ‹é‡ç±»å‹
        """
        if not self.client_available:
            return pd.DataFrame()
        
        log_section(self.logger, f"æ­¥éª¤2: é‡‡æ ·è´Ÿæ ·æœ¬ (ç›®æ ‡{n_needed}ä¸ª)")
        
        try:
            # æ‰©å±•é¶ç‚¹åˆ—è¡¨ï¼ˆ10ä¸ªä¸åŒå®¶æ—ï¼‰
            diverse_targets = [
                ('CHEMBL1862', 'JAK2', 'Kinase'),
                ('CHEMBL203', 'EGFR', 'RTK'),
                ('CHEMBL1824', 'Cathepsin', 'Protease'),
                ('CHEMBL1951', 'hERG', 'Ion_Channel'),
                ('CHEMBL2035', 'CCR5', 'GPCR'),
                ('CHEMBL1075104', 'PDE4', 'Enzyme'),
                ('CHEMBL1955', 'AKT1', 'Kinase'),
                ('CHEMBL2095192', 'HDAC1', 'Epigenetic'),
                ('CHEMBL3371', 'NOS', 'Enzyme'),
                ('CHEMBL340', 'Tubulin', 'Structural'),
            ]
            
            all_negatives = []
            samples_per_target = (n_needed // len(diverse_targets)) + 300  # æ›´å¤šå¤‡ç”¨
            
            for target_id, target_name, family in diverse_targets:
                try:
                    self.logger.info(f"\n  é‡‡æ ·è‡ª {target_name} ({family})...")
                    
                    # æ‰©å±•é‡‡æ ·ç­–ç•¥
                    activities = self.chembl.activity.filter(
                        target_chembl_id=target_id,
                        standard_type__in=['IC50', 'EC50', 'Ki'],  # å¤šç§ç±»å‹
                        standard_relation='>',
                        standard_value__gte=10000
                    ).only([
                        'molecule_chembl_id',
                        'canonical_smiles',
                        'standard_type',
                        'standard_relation',
                        'standard_value',
                        'standard_units'
                    ])
                    
                    data = list(activities)[:samples_per_target]
                    
                    if data:
                        df_temp = pd.DataFrame(data)
                        df_temp['data_source'] = 'Sampled_Negative'
                        df_temp['source_detail'] = f"{family}_{target_name}"
                        all_negatives.append(df_temp)
                        self.logger.info(f"    âœ“ è·å– {len(df_temp)}")
                    
                    time.sleep(1)
                    
                except Exception as e:
                    self.logger.warning(f"    é‡‡æ · {target_name} å¤±è´¥: {e}")
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å¤Ÿäº†
                if all_negatives:
                    total = sum(len(df) for df in all_negatives)
                    if total >= n_needed * 1.2:
                        break
            
            if all_negatives:
                df_neg = pd.concat(all_negatives, ignore_index=True)
                
                # å»é‡
                initial_count = len(df_neg)
                df_neg = df_neg.drop_duplicates(subset=['canonical_smiles'], keep='first')
                self.logger.info(f"\n  å»é‡: {initial_count} â†’ {len(df_neg)}")
                
                # é‡‡æ ·åˆ°ç›®æ ‡
                if len(df_neg) > n_needed:
                    df_neg = df_neg.sample(n=n_needed, random_state=42)
                
                self.logger.info(f"\nâœ“ è´Ÿæ ·æœ¬é‡‡é›†å®Œæˆ: {len(df_neg)}")
                return df_neg
            else:
                return pd.DataFrame()
                
        except Exception as e:
            self.logger.error(f"é‡‡æ ·å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def generate_realistic_data(self, n_active: int, n_inactive: int) -> pd.DataFrame:
        """ç”Ÿæˆé«˜è´¨é‡ç¤ºä¾‹æ•°æ®ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰"""
        self.logger.info(f"\nç”Ÿæˆç¤ºä¾‹æ•°æ®:")
        self.logger.info(f"  æ´»æ€§: {n_active}")
        self.logger.info(f"  éæ´»æ€§: {n_inactive}")
        
        np.random.seed(42)
        
        # çœŸå®NLRP3æŠ‘åˆ¶å‰‚æ ¸å¿ƒç»“æ„
        active_scaffolds = [
            "c1ccc2c(c1)c(c(s2)S(=O)(=O)N)NC(=O)C",
            "c1ccc(cc1)S(=O)(=O)Nc2nccs2",
            "COc1ccc(cc1)C(=O)Nc2ccc(cc2)S(=O)(=O)N",
            "c1ccc(cc1)c2nnc(s2)SCC(=O)N",
            "Cc1ccc(cc1)S(=O)(=O)Nc2ncccn2",
            "c1ccc2c(c1)nc(s2)NC(=O)c3ccccc3",
        ]
        
        inactive_scaffolds = [
            "c1ccccc1", "CCCCc1ccccc1", "c1ccc(cc1)O",
            "COc1ccccc1", "c1ccc(cc1)C(=O)O", "CCCCn1ccnc1",
            "c1ccc2c(c1)cccn2", "c1ccc(cc1)N", "c1ccc(cc1)Cl",
        ]
        
        data = []
        
        # ç”Ÿæˆæ´»æ€§
        for i in range(n_active):
            scaffold = np.random.choice(active_scaffolds)
            
            dist = np.random.choice(['potent', 'moderate', 'weak'], p=[0.2, 0.6, 0.2])
            
            if dist == 'potent':
                ic50_nm = np.random.lognormal(np.log(50), 0.5)
                ic50_nm = np.clip(ic50_nm, 10, 100)
            elif dist == 'moderate':
                ic50_nm = np.random.lognormal(np.log(800), 0.8)
                ic50_nm = np.clip(ic50_nm, 100, 5000)
            else:
                ic50_nm = np.random.lognormal(np.log(12000), 0.4)
                ic50_nm = np.clip(ic50_nm, 5000, 20000)
            
            assay_type = np.random.choice(['IC50', 'EC50', 'Ki'], p=[0.7, 0.2, 0.1])
            relation = '='
            
            data.append({
                'molecule_chembl_id': f'CHEMBL{1000000+i}',
                'canonical_smiles': scaffold,
                'standard_type': assay_type,
                'standard_relation': relation,
                'standard_value': ic50_nm,
                'standard_units': 'nM',
                'pchembl_value': -np.log10(ic50_nm / 1e9),
                'data_source': 'Example_Active',
                'source_detail': 'Generated'
            })
        
        # ç”Ÿæˆéæ´»æ€§
        for i in range(n_inactive):
            scaffold = np.random.choice(inactive_scaffolds)
            ic50_nm = np.random.uniform(20000, 100000)
            relation = np.random.choice(['=', '>'], p=[0.3, 0.7])
            
            if relation == '>':
                ic50_nm = np.random.choice([10000, 20000, 50000])
            
            data.append({
                'molecule_chembl_id': f'CHEMBL{3000000+i}',
                'canonical_smiles': scaffold,
                'standard_type': 'IC50',
                'standard_relation': relation,
                'standard_value': ic50_nm,
                'standard_units': 'nM',
                'pchembl_value': -np.log10(ic50_nm / 1e9) if relation == '=' else None,
                'data_source': 'Example_Inactive',
                'source_detail': 'Generated'
            })
        
        df = pd.DataFrame(data)
        return df.sample(frac=1, random_state=42).reset_index(drop=True)
    
    def run(self) -> str:
        """è¿è¡Œå®Œæ•´é‡‡é›†æµç¨‹"""
        log_section(self.logger, "ä¼˜åŒ–æ•°æ®é‡‡é›†")
        
        all_data = []
        
        # 1. ä¸‹è½½NLRP3æ•°æ®
        nlrp3_data = self.download_nlrp3_data_comprehensive()
        
        if len(nlrp3_data) > 0:
            all_data.append(nlrp3_data)
            
            # å¦‚æœä¸å¤Ÿï¼Œè¡¥å……ç¤ºä¾‹æ•°æ®
            shortage = max(0, self.raw_nlrp3_needed - len(nlrp3_data))
            if shortage > 0:
                self.logger.warning(f"\nNLRP3æ•°æ®ä¸è¶³ï¼Œè¡¥å……{shortage}æ¡ç¤ºä¾‹æ•°æ®")
                supplement = self.generate_realistic_data(
                    n_active=shortage,
                    n_inactive=0
                )
                all_data.append(supplement)
            
            # 2. é‡‡æ ·è´Ÿæ ·æœ¬
            negative_data = self.sample_negative_compounds_aggressive(self.raw_inactive_needed)
            
            if len(negative_data) > 0:
                all_data.append(negative_data)
            else:
                self.logger.warning("è´Ÿæ ·æœ¬é‡‡é›†å¤±è´¥ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")
                neg_supplement = self.generate_realistic_data(
                    n_active=0,
                    n_inactive=self.raw_inactive_needed
                )
                all_data.append(neg_supplement)
        else:
            # ChEMBLå®Œå…¨ä¸å¯ç”¨
            self.logger.warning("ChEMBLä¸å¯ç”¨ï¼Œä½¿ç”¨å®Œæ•´ç¤ºä¾‹æ•°æ®")
            example_data = self.generate_realistic_data(
                n_active=self.raw_nlrp3_needed,
                n_inactive=self.raw_inactive_needed
            )
            all_data.append(example_data)
        
        # åˆå¹¶å¹¶ä¿å­˜
        final_df = pd.concat(all_data, ignore_index=True)
        
        output_dir = self.config['paths']['raw_data_dir']
        output_file = self.config['filenames']['raw_data']
        output_path = Path(output_dir) / output_file
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        final_df.to_csv(output_path, index=False)
        
        # æœ€ç»ˆæŠ¥å‘Š
        log_section(self.logger, "é‡‡é›†å®Œæˆ")
        
        self.logger.info(f"æ€»è®°å½•æ•°: {len(final_df)}")
        self.logger.info(f"ç›®æ ‡: NLRP3={self.raw_nlrp3_needed}, éæ´»æ€§={self.raw_inactive_needed}")
        
        if 'data_source' in final_df.columns:
            self.logger.info(f"\næ•°æ®æ¥æº:")
            for source, count in final_df['data_source'].value_counts().items():
                pct = count / len(final_df) * 100
                self.logger.info(f"  {source}: {count} ({pct:.1f}%)")
        
        self.logger.info(f"\nä¿å­˜ä½ç½®: {output_path}")
        
        return str(output_path)


def main():
    """ä¸»å‡½æ•°"""
    config = load_data_config()
    
    collector = OptimizedDataCollector(config)
    output_path = collector.run()
    
    print(f"\n{'='*70}")
    print("âœ… æ•°æ®é‡‡é›†å®Œæˆ")
    print(f"{'='*70}")
    print(f"\nğŸ“ æ–‡ä»¶: {output_path}")
    print("\nğŸ’¡ æ”¹è¿›è¯´æ˜:")
    print("  âœ“ å…¨é¢æœç´¢æ‰€æœ‰NLRP3ç›¸å…³é¶ç‚¹")
    print("  âœ“ åŒ…å«æ‰€æœ‰æµ‹é‡ç±»å‹")
    print("  âœ“ æ¿€è¿›çš„è¿‡é‡‡æ ·ç­–ç•¥")
    print("  âœ“ å……åˆ†è€ƒè™‘é¢„å¤„ç†æŸå¤±")
    print("\nğŸ“Š ä¸‹ä¸€æ­¥:")
    print("  python experiments/stage0_data/02_preprocess_data.py")


if __name__ == "__main__":
    main()