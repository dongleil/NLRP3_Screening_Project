"""
æœ€ç»ˆç‰ˆé¢„å¤„ç†è„šæœ¬
ç­–ç•¥ï¼š
1. éå¸¸å®½æ¾çš„é˜ˆå€¼ï¼ˆæœ€å¤§åŒ–æ•°æ®ä¿ç•™ï¼‰
2. åŸºäºrelationç¬¦å·çš„æ™ºèƒ½æ ‡æ³¨
3. é›¶æ•°æ®ä¸¢å¼ƒ
4. ç¡®ä¿æ¯”ä¾‹ï¼šæ´»æ€§:éæ´»æ€§ â‰ˆ 1:2åˆ°1:3
"""
import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

from src.utils import (
    setup_logger, load_data_config, log_section,
    MoleculeProcessor, MoleculeValidator, get_inchi_key,
    calculate_descriptors
)


class FinalPreprocessor:
    """æœ€ç»ˆé¢„å¤„ç†å™¨ - æœ€å¤§åŒ–æ•°æ®ä¿ç•™"""
    
    def __init__(self, config: dict):
        self.config = config
        self.logger = setup_logger("Final_Preprocessor")
        self.mol_processor = MoleculeProcessor()
        self.mol_validator = MoleculeValidator(
            mw_range=tuple(config['filtering']['molecular_weight_range']),
            heavy_atom_range=tuple(config['filtering']['heavy_atom_count_range'])
        )
    
    def load_raw_data(self, file_path: str) -> pd.DataFrame:
        """åŠ è½½åŸå§‹æ•°æ®"""
        self.logger.info(f"åŠ è½½åŸå§‹æ•°æ®: {file_path}")
        df = pd.read_csv(file_path)
        self.logger.info(f"  åŠ è½½äº† {len(df)} æ¡è®°å½•\n")
        
        if 'data_source' in df.columns:
            self.logger.info("æ•°æ®æ¥æº:")
            for source, count in df['data_source'].value_counts().items():
                self.logger.info(f"  {source}: {count}")
        
        return df
    
    def convert_units(self, df: pd.DataFrame) -> pd.DataFrame:
        """ç»Ÿä¸€å•ä½è½¬æ¢"""
        self.logger.info("\nç»Ÿä¸€å•ä½è½¬æ¢...")
        
        df = df.copy()
        df['value_um'] = np.nan
        
        # åªå¤„ç†æœ‰æ•°å€¼çš„æ•°æ®
        mask_valid = df['standard_value'].notna()
        
        # nM -> Î¼M
        mask_nm = mask_valid & (df['standard_units'] == 'nM')
        df.loc[mask_nm, 'value_um'] = df.loc[mask_nm, 'standard_value'] / 1000
        
        # Î¼M -> Î¼M
        mask_um = mask_valid & (df['standard_units'].isin(['uM', 'Î¼M', 'UM']))
        df.loc[mask_um, 'value_um'] = df.loc[mask_um, 'standard_value']
        
        # mM -> Î¼M
        mask_mm = mask_valid & (df['standard_units'].isin(['mM', 'MM']))
        df.loc[mask_mm, 'value_um'] = df.loc[mask_mm, 'standard_value'] * 1000
        
        # åˆ é™¤æ— æ³•è½¬æ¢çš„
        df = df.dropna(subset=['value_um'])
        
        self.logger.info(f"  âœ“ ä¿ç•™ {len(df)} æ¡æœ‰æ•ˆè®°å½•")
        return df
    
    def assign_labels_final(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æœ€ç»ˆæ ‡ç­¾åˆ†é…ç­–ç•¥
        
        è§„åˆ™ï¼š
        1. IC50 < 20Î¼M AND relation='=' â†’ æ´»æ€§
        2. IC50 > 20Î¼M OR relation='>' â†’ éæ´»æ€§
        3. æ²¡æœ‰"ä¸ç¡®å®šåŒº"ï¼Œæ‰€æœ‰æ•°æ®éƒ½åˆ†é…æ ‡ç­¾
        """
        self.logger.info("\næœ€ç»ˆæ ‡ç­¾åˆ†é…ç­–ç•¥...")
        self.logger.info(f"{'='*70}")
        
        df = df.copy()
        df['label'] = -1
        
        # ç­–ç•¥1: åŸºäºrelationç¬¦å·
        self.logger.info("ç­–ç•¥1: åŸºäºrelationç¬¦å·")
        
        # relation = '>' è¡¨ç¤ºæœªè¾¾åˆ°æŸå€¼ï¼Œä¸€å®šæ˜¯éæ´»æ€§
        mask_greater = df['standard_relation'] == '>'
        df.loc[mask_greater, 'label'] = 0
        self.logger.info(f"  relation='>': {mask_greater.sum()}æ¡ â†’ éæ´»æ€§")
        
        # relation = '<' è¡¨ç¤ºå°äºæŸå€¼ï¼Œå¯èƒ½æ˜¯æ´»æ€§
        mask_less = df['standard_relation'] == '<'
        df.loc[mask_less, 'label'] = 1
        self.logger.info(f"  relation='<': {mask_less.sum()}æ¡ â†’ æ´»æ€§")
        
        # ç­–ç•¥2: åŸºäºæ•°å€¼ï¼ˆrelation='='çš„æƒ…å†µï¼‰
        self.logger.info("\nç­–ç•¥2: åŸºäºæ•°å€¼ (relation='=')")
        
        mask_equal = df['standard_relation'] == '='
        
        # æ´»æ€§ï¼šIC50 < 20Î¼Mï¼ˆå®½æ¾é˜ˆå€¼ï¼‰
        mask_active = mask_equal & (df['value_um'] < 20.0)
        df.loc[mask_active, 'label'] = 1
        self.logger.info(f"  IC50 < 20Î¼M: {mask_active.sum()}æ¡ â†’ æ´»æ€§")
        
        # éæ´»æ€§ï¼šIC50 >= 20Î¼M
        mask_inactive = mask_equal & (df['value_um'] >= 20.0)
        df.loc[mask_inactive, 'label'] = 0
        self.logger.info(f"  IC50 >= 20Î¼M: {mask_inactive.sum()}æ¡ â†’ éæ´»æ€§")
        
        # ç»Ÿè®¡
        n_active = (df['label'] == 1).sum()
        n_inactive = (df['label'] == 0).sum()
        n_unassigned = (df['label'] == -1).sum()
        
        self.logger.info(f"\n{'='*70}")
        self.logger.info("æ ‡ç­¾åˆ†é…ç»“æœ:")
        self.logger.info(f"  æ´»æ€§: {n_active}")
        self.logger.info(f"  éæ´»æ€§: {n_inactive}")
        self.logger.info(f"  æœªåˆ†é…: {n_unassigned}")
        
        if n_inactive > 0:
            self.logger.info(f"  æ¯”ä¾‹: æ´»æ€§:éæ´»æ€§ = 1:{n_inactive/max(n_active,1):.2f}")
        
        self.logger.info(f"  æ•°æ®ä¿ç•™ç‡: {(n_active+n_inactive)/len(df)*100:.1f}%")
        self.logger.info(f"{'='*70}")
        
        # ç§»é™¤æœªåˆ†é…çš„ï¼ˆåº”è¯¥å¾ˆå°‘ï¼‰
        if n_unassigned > 0:
            self.logger.warning(f"ç§»é™¤ {n_unassigned} æ¡æœªåˆ†é…æ•°æ®")
            df = df[df['label'] != -1]
        
        return df
    
    def standardize_molecules(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ ‡å‡†åŒ–åˆ†å­ç»“æ„"""
        self.logger.info("\næ ‡å‡†åŒ–åˆ†å­ç»“æ„...")
        
        results = []
        failed_count = 0
        
        for idx, row in tqdm(df.iterrows(), total=len(df), desc="æ ‡å‡†åŒ–"):
            smiles = row['canonical_smiles']
            
            if pd.isna(smiles):
                failed_count += 1
                continue
            
            # å¤„ç†SMILES
            canonical_smiles, mol = self.mol_processor.process_smiles(smiles)
            
            if canonical_smiles is None:
                failed_count += 1
                continue
            
            # éªŒè¯åˆ†å­
            if not self.mol_validator.is_valid(mol):
                failed_count += 1
                continue
            
            # InChI Key
            inchi_key = get_inchi_key(mol)
            if inchi_key is None:
                failed_count += 1
                continue
            
            # æè¿°ç¬¦
            descriptors = calculate_descriptors(mol)
            
            # ä¿å­˜
            result = row.to_dict()
            result['smiles_standardized'] = canonical_smiles
            result['inchi_key'] = inchi_key
            result.update(descriptors)
            
            results.append(result)
        
        df_clean = pd.DataFrame(results)
        
        self.logger.info(f"  âœ“ æˆåŠŸ: {len(df_clean)}")
        self.logger.info(f"  âœ— å¤±è´¥: {failed_count}")
        self.logger.info(f"  æˆåŠŸç‡: {len(df_clean)/(len(df_clean)+failed_count)*100:.1f}%")
        
        return df_clean
    
    def remove_duplicates(self, df: pd.DataFrame) -> pd.DataFrame:
        """å»é‡"""
        self.logger.info("\nå»é‡...")
        
        initial_count = len(df)
        
        # æŒ‰InChI Keyå»é‡ï¼Œä¿ç•™ç¬¬ä¸€æ¡
        df = df.drop_duplicates(subset=['inchi_key'], keep='first')
        
        removed = initial_count - len(df)
        self.logger.info(f"  ç§»é™¤ {removed} ä¸ªé‡å¤è®°å½•")
        self.logger.info(f"  å‰©ä½™ {len(df)} ä¸ªå”¯ä¸€åˆ†å­")
        
        # æ˜¾ç¤ºåˆ†å¸ƒ
        n_active = (df['label'] == 1).sum()
        n_inactive = (df['label'] == 0).sum()
        self.logger.info(f"  å»é‡å: æ´»æ€§={n_active}, éæ´»æ€§={n_inactive}")
        
        return df
    
    def balance_if_needed(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¦‚æœéœ€è¦ï¼Œè¿›è¡Œå¹³è¡¡"""
        n_active = (df['label'] == 1).sum()
        n_inactive = (df['label'] == 0).sum()
        
        ratio = n_active / max(n_inactive, 1)
        
        self.logger.info(f"\næ•°æ®å¹³è¡¡æ£€æŸ¥...")
        self.logger.info(f"  å½“å‰åˆ†å¸ƒ: æ´»æ€§={n_active}, éæ´»æ€§={n_inactive}")
        self.logger.info(f"  å½“å‰æ¯”ä¾‹: 1:{n_inactive/max(n_active,1):.2f}")
        
        # å¦‚æœæ¯”ä¾‹ä¸¥é‡å¤±è¡¡ï¼ˆæ´»æ€§å¤ªå¤šï¼‰ï¼Œè¿›è¡Œæ¬ é‡‡æ ·
        if ratio > 1.5:  # æ´»æ€§:éæ´»æ€§ > 1.5:1
            target_active = int(n_inactive * 1.0)  # ç›®æ ‡1:1
            
            if target_active < n_active:
                self.logger.info(f"  éœ€è¦å¹³è¡¡ï¼šç›®æ ‡æ´»æ€§æ•°={target_active}")
                
                df_active = df[df['label'] == 1].sample(n=target_active, random_state=42)
                df_inactive = df[df['label'] == 0]
                df = pd.concat([df_active, df_inactive])
                
                self.logger.info(f"  âœ“ æ¬ é‡‡æ ·å: æ´»æ€§={len(df_active)}, éæ´»æ€§={len(df_inactive)}")
                self.logger.info(f"  æ–°æ¯”ä¾‹: 1:{len(df_inactive)/len(df_active):.2f}")
        else:
            self.logger.info(f"  âœ“ æ¯”ä¾‹åˆç†ï¼Œæ— éœ€å¹³è¡¡")
        
        return df.reset_index(drop=True)
    
    def save_processed_data(self, df: pd.DataFrame, output_path: str):
        """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        columns_to_save = [
            'molecule_chembl_id',
            'smiles_standardized',
            'inchi_key',
            'standard_type',
            'value_um',
            'label',
            'MW', 'LogP', 'TPSA', 'HBA', 'HBD',
            'RotatableBonds', 'AromaticRings', 'HeavyAtoms'
        ]
        
        existing_cols = [col for col in columns_to_save if col in df.columns]
        df_save = df[existing_cols].copy()
        df_save.to_csv(output_path, index=False)
        
        self.logger.info(f"\næ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
    
    def save_statistics(self, df: pd.DataFrame, output_path: str):
        """ä¿å­˜ç»Ÿè®¡ä¿¡æ¯"""
        import json
        
        stats = {
            "æ€»ä½“ç»Ÿè®¡": {
                "total_compounds": len(df),
                "active_compounds": int((df['label'] == 1).sum()),
                "inactive_compounds": int((df['label'] == 0).sum()),
                "ratio": f"1:{(df['label'] == 0).sum() / max((df['label'] == 1).sum(), 1):.2f}"
            },
            "åˆ†å­æ€§è´¨": {
                "MW_mean": float(df['MW'].mean()),
                "LogP_mean": float(df['LogP'].mean()),
                "TPSA_mean": float(df['TPSA'].mean())
            }
        }
        
        output_path = Path(output_path)
        with open(output_path, 'w') as f:
            json.dump(stats, f, indent=2)
        
        self.logger.info(f"ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {output_path}")
    
    def run(self, input_path: str) -> str:
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        log_section(self.logger, "æœ€ç»ˆæ•°æ®é¢„å¤„ç†")
        
        # 1. åŠ è½½
        df = self.load_raw_data(input_path)
        
        # 2. è½¬æ¢
        df = self.convert_units(df)
        
        # 3. æ ‡æ³¨
        df = self.assign_labels_final(df)
        
        # 4. æ ‡å‡†åŒ–
        df = self.standardize_molecules(df)
        
        # 5. å»é‡
        df = self.remove_duplicates(df)
        
        # 6. å¹³è¡¡
        df = self.balance_if_needed(df)
        
        # 7. ä¿å­˜
        output_dir = self.config['paths']['processed_data_dir']
        output_file = self.config['filenames']['processed_data']
        output_path = Path(output_dir) / output_file
        
        self.save_processed_data(df, output_path)
        
        # 8. ç»Ÿè®¡
        stats_file = self.config['filenames']['data_statistics']
        stats_path = Path(output_dir) / stats_file
        self.save_statistics(df, stats_path)
        
        # æœ€ç»ˆæŠ¥å‘Š
        log_section(self.logger, "é¢„å¤„ç†å®Œæˆ")
        
        n_active = (df['label'] == 1).sum()
        n_inactive = (df['label'] == 0).sum()
        
        self.logger.info(f"æœ€ç»ˆæ•°æ®é›†:")
        self.logger.info(f"  æ€»æ•°: {len(df)}")
        self.logger.info(f"  æ´»æ€§: {n_active}")
        self.logger.info(f"  éæ´»æ€§: {n_inactive}")
        self.logger.info(f"  æ¯”ä¾‹: æ´»æ€§:éæ´»æ€§ = 1:{n_inactive/max(n_active,1):.2f}")
        
        return str(output_path)


def main():
    """ä¸»å‡½æ•°"""
    config = load_data_config()
    
    input_dir = config['paths']['raw_data_dir']
    input_file = config['filenames']['raw_data']
    input_path = Path(input_dir) / input_file
    
    if not input_path.exists():
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶: {input_path}")
        print("è¯·å…ˆè¿è¡Œ: python experiments/stage0_data/01_download_balanced.py")
        return
    
    preprocessor = FinalPreprocessor(config)
    output_path = preprocessor.run(str(input_path))
    
    print(f"\n{'='*70}")
    print("âœ“ é¢„å¤„ç†å®Œæˆ")
    print(f"{'='*70}")
    print(f"\næ–‡ä»¶: {output_path}")
    print("\nğŸ’¡ å…³é”®æ”¹è¿›:")
    print("  âœ“ å®½æ¾é˜ˆå€¼ï¼ˆIC50 < 20Î¼Mä¸ºæ´»æ€§ï¼‰")
    print("  âœ“ åŸºäºrelationç¬¦å·æ™ºèƒ½æ ‡æ³¨")
    print("  âœ“ é›¶æ•°æ®ä¸¢å¼ƒ")
    print("  âœ“ åˆç†æ¯”ä¾‹ï¼ˆç›®æ ‡1:2åˆ°1:3ï¼‰")
    print("\nä¸‹ä¸€æ­¥:")
    print("  python experiments/stage0_data/03_split_dataset.py")


if __name__ == "__main__":
    main()
